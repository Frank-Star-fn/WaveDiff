# Official PyTorch implementation of "Wavelet Diffusion Models are fast and scalable Image Generators"

<!-- <div align="center">
  <a href="https://xavierxiao.github.io/" target="_blank">Zhisheng&nbsp;Xiao</a> &emsp; <b>&middot;</b> &emsp;
  <a href="https://karstenkreis.github.io/" target="_blank">Karsten&nbsp;Kreis</a> &emsp; <b>&middot;</b> &emsp;
  <a href="http://latentspace.cc/arash_vahdat/" target="_blank">Arash&nbsp;Vahdat</a>
  <br> <br>
  <a href="https://nvlabs.github.io/denoising-diffusion-gan/" target="_blank">Project&nbsp;Page</a>
</div>
<br>
<br> -->

<div align="center">
    <img width="1000" alt="teaser" src="assets/single_wavelet.png"/>
</div>

**Abstract:**
Diffusion models are rising as a powerful solution for high-fidelity image generation, which exceeds GANs in quality in many circumstances. However, their slow training and inference speed is a huge bottleneck, blocking them from being used in real-time applications. A recent DiffusionGAN method significantly decreases the models' running time by reducing the number of sampling steps from thousands to several, but their speeds still largely lag behind the GAN counterparts. This paper aims to reduce the speed gap by proposing a novel wavelet-based diffusion structure. We extract low-and-high frequency components from both image and feature levels via wavelet decomposition and adaptively handle these components for faster processing while maintaining good generation quality. Furthermore, we propose to use a reconstruction term, which effectively boosts the model training convergence. Experimental results on CelebA-HQ, CIFAR-10, LSUN-Church, and STL-10 datasets prove our solution is a stepping-stone to offering real-time and high-fidelity diffusion models.

## Installation ##
Latest Pytorch version is required. 

Install neccessary libraries:
```
pip install -r requirements.txt
```
For `pytorch_wavelets`, please follow [here](https://github.com/fbcotter/pytorch_wavelets.git).

## Set up datasets ##
We trained on several datasets, including CIFAR10, STL10, LSUN Church Outdoor 256 and CelebA HQ (256 & 512). 
Please check [here](https://github.com/NVlabs/NVAE#set-up-file-paths-and-data) for dataset preparation.


## How to run ##
We provide a bash script for our experiments on different datasets. The syntax is following:
```
bash run.sh <DATASET> <MODE> <#GPUS>
```
where: 
- `<DATASET>`: "cifar10", "stl10", "celeba_256", "celeba_512", and "lsun".
- `<MODE>`: "train" and "test".
- `<#GPUS>`: the number of gpus (e.g. 1, 2, 4, 8).

Note, please set agrument `-exp` correspondingly for both "train" and "test" mode.

## Pretrained Checkpoints ##
We have released pretrained checkpoints on CIFAR-10 and CelebA HQ 256 at this 
[Google drive directory](https://drive.google.com/drive/folders/1UkzsI0SwBRstMYysRdR76C1XdSv5rQNz?usp=sharing).
Simply download the `saved_info` directory to the code directory. Use `--epoch_id 1200` for CIFAR-10 and `--epoch_id 550`
for CelebA HQ 256 in the commands below.

## Inference ##
Samples can be generated by calling in [run.sh](./run.sh) with "test" mode.

## Evaluation ##
### FID ###
To compute fid of pretrained models on a specific epoch, we can add additional arguments including ```--compute_fid``` and ```--real_img_dir /path/to/real/images``` of the corresponding experiments in [run.sh](./run.sh).

### Recall ###
We adopt the official Pytorch implementation of [StyleGAN2-ADA](https://github.com/NVlabs/stylegan2-ada-pytorch.git) to compute Recall of generated samples.

## License ##
This repository is released under the Apache 2.0 license as found in the LICENSE file.

## Bibtex ##
Cite our paper using the following bibtex item:

```
@inproceedings{
xiao2022tackling,
title={Tackling the Generative Learning Trilemma with Denoising Diffusion GANs},
author={Zhisheng Xiao and Karsten Kreis and Arash Vahdat},
booktitle={International Conference on Learning Representations},
year={2022}
}
```
